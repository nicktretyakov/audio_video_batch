# ğŸ¬ Video-Audio Processor

## âœ¨ Features

### ğŸ¥ Video Processing
- **Frame Extraction**: High-quality frame extraction from any video format
- **Object Detection**: ML-powered object recognition with bounding boxes
- **Batch Processing**: Process multiple videos automatically
- **Format Support**: MP4, AVI, MOV, MKV, WMV, FLV, WebM

### ğŸµ Audio Processing
- **Audio Extraction**: Clean audio stream extraction
- **Speech Recognition**: Transcribe spoken content with timestamps
- **Multi-language Support**: Configurable language models
- **Audio Analysis**: Frequency and amplitude analysis

### ğŸ¤– Machine Learning Backends
- **Mock Backend**: Realistic test data for development (default)
- **PyTorch**: Full deep learning with GPU acceleration
- **ONNX Runtime**: Cross-platform ML inference
- **Candle**: Rust-native ML framework

### ğŸ”„ Synchronization & Output
- **Timestamp Sync**: Precise alignment of video and audio analysis
- **Multiple Formats**: JSON, CSV, TXT output options
- **Batch Reports**: Comprehensive processing summaries
- **Real-time Progress**: Live progress tracking


# Run automated setup
chmod +x build-with-fallback.sh
./build-with-fallback.sh

# Process a single video
echo "Place your video as input.mp4"
cargo run single

# Process multiple videos
mkdir input_videos
# Add your videos to input_videos/
cargo run batch

### Option 2: Docker (Zero Setup)
# Setup and build
./docker-setup.sh
./docker-build.sh all

# Process videos
./docker-run.sh basic batch

### Option 3: Manual Installation
# Install dependencies (Ubuntu/Debian)
sudo apt-get install libavformat-dev libavcodec-dev libavutil-dev libswscale-dev

# Install dependencies (macOS)
brew install ffmpeg

# Build and run
cargo build --features mock-ml
cargo run batch

## ğŸ“‹ Prerequisites

# Or manually choose features
cargo build --features mock-ml      # Recommended for testing
cargo build --features pytorch      # Requires PyTorch
cargo build --features onnx         # Requires ONNX Runtime
cargo build --features candle       # Rust-native ML

# With custom options
cargo run single --confidence 0.7 --save-frames

# Process all videos
cargo run batch

# Process with PyTorch (GPU acceleration)
./docker-run.sh pytorch batch

# Start web interface
./docker-run.sh web web
# Open http://localhost:8080

# Custom configuration
export MAX_CONCURRENT_VIDEOS=8
export CONFIDENCE_THRESHOLD=0.8
cargo run batch

## ğŸ“ Project Structure


video-audio-processor/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs              # Main application entry
â”‚   â”œâ”€â”€ video_processor.rs   # Video frame extraction
â”‚   â”œâ”€â”€ frame_analyzer.rs    # ML frame analysis
â”‚   â”œâ”€â”€ audio_processor.rs   # Audio extraction & transcription
â”‚   â”œâ”€â”€ ml_backend.rs        # ML backend abstraction
â”‚   â”œâ”€â”€ batch_processor.rs   # Batch processing logic
â”‚   â””â”€â”€ synchronizer.rs      # Result synchronization
â”œâ”€â”€ input_videos/            # Place videos here for batch processing
â”œâ”€â”€ output_results/          # Processing results appear here
â”œâ”€â”€ models/                  # ML model files
â”œâ”€â”€ docker/                  # Docker configurations
â”œâ”€â”€ scripts/                 # Utility scripts
â””â”€â”€ docs/                    # Documentation

